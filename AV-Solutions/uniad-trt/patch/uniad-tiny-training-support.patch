diff --git a/projects/configs/stage1_track_map/base_track_map.py b/projects/configs/stage1_track_map/base_track_map.py
index 0f056d4..433de42 100644
--- a/projects/configs/stage1_track_map/base_track_map.py
+++ b/projects/configs/stage1_track_map/base_track_map.py
@@ -63,10 +63,6 @@ occ_n_future_max = max([occ_n_future, occ_n_future_plan])
 ### planning ###
 planning_steps = 6
 use_col_optim = True
-# there exists multiple interpretations of the planning metric, where it differs between uniad and stp3/vad
-# uniad: computed at a particular time (e.g., L2 distance between the predicted and ground truth future trajectory at time 3.0s)
-# stp3: computed as the average up to a particular time (e.g., average L2 distance between the predicted and ground truth future trajectory up to 3.0s)
-planning_evaluation_strategy = "uniad"  # uniad or stp3
 
 ### Occ args ### 
 occflow_grid_conf = {
@@ -74,6 +70,7 @@ occflow_grid_conf = {
     'ybound': [-50.0, 50.0, 0.5],
     'zbound': [-10.0, 10.0, 20.0],
 }
+evaluation_ranges = {'30x30': (70, 130), '100x100': (0, 200)}
 
 # Other settings
 train_gt_iou_threshold=0.3
@@ -574,11 +571,7 @@ lr_config = dict(
     min_lr_ratio=1e-3,
 )
 total_epochs = 6
-evaluation = dict(
-    interval=6,
-    pipeline=test_pipeline,
-    planning_evaluation_strategy=planning_evaluation_strategy,
-)
+evaluation = dict(interval=6, pipeline=test_pipeline)
 runner = dict(type="EpochBasedRunner", max_epochs=total_epochs)
 log_config = dict(
     interval=10, hooks=[dict(type="TextLoggerHook"), dict(type="TensorboardLoggerHook")]
diff --git a/projects/configs/stage2_e2e/base_e2e.py b/projects/configs/stage2_e2e/base_e2e.py
index 9903440..ffd2c90 100644
--- a/projects/configs/stage2_e2e/base_e2e.py
+++ b/projects/configs/stage2_e2e/base_e2e.py
@@ -55,10 +55,6 @@ occ_n_future_max = max([occ_n_future, occ_n_future_plan])
 ### planning ###
 planning_steps = 6
 use_col_optim = True
-# there exists multiple interpretations of the planning metric, where it differs between uniad and stp3/vad
-# uniad: computed at a particular time (e.g., L2 distance between the predicted and ground truth future trajectory at time 3.0s)
-# stp3: computed as the average up to a particular time (e.g., average L2 distance between the predicted and ground truth future trajectory up to 3.0s)
-planning_evaluation_strategy = "uniad"  # uniad or stp3
 
 ### Occ args ### 
 occflow_grid_conf = {
@@ -66,6 +62,7 @@ occflow_grid_conf = {
     'ybound': [-50.0, 50.0, 0.5],
     'zbound': [-10.0, 10.0, 20.0],
 }
+evaluation_ranges = {'30x30': (70, 130), '100x100': (0, 200)}
 
 # Other settings
 train_gt_iou_threshold=0.3
@@ -689,16 +686,12 @@ lr_config = dict(
     min_lr_ratio=1e-3,
 )
 total_epochs = 20
-evaluation = dict(
-    interval=4,
-    pipeline=test_pipeline,
-    planning_evaluation_strategy=planning_evaluation_strategy,
-)
+evaluation = dict(interval=30, pipeline=test_pipeline)
 runner = dict(type="EpochBasedRunner", max_epochs=total_epochs)
 log_config = dict(
     interval=10, hooks=[dict(type="TextLoggerHook"), dict(type="TensorboardLoggerHook")]
 )
 checkpoint_config = dict(interval=1)
-load_from = "ckpts/uniad_base_track_map.pth"
+load_from = "ckpts/base_track_map.pth"
 
 find_unused_parameters = True
\ No newline at end of file
diff --git a/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py b/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
index 583fcab..43c01b7 100755
--- a/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
+++ b/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
@@ -13,7 +13,7 @@ except ImportError:
     linear_sum_assignment = None
 
 
-@BBOX_ASSIGNERS.register_module()
+@BBOX_ASSIGNERS.register_module(force=True)
 class HungarianAssigner3D(BaseAssigner):
     """Computes one-to-one matching between predictions and ground truth.
     This class computes an assignment between the targets and the predictions
diff --git a/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d_track.py b/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d_track.py
index 5067730..e70c573 100644
--- a/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d_track.py
+++ b/projects/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d_track.py
@@ -10,7 +10,7 @@ except ImportError:
     linear_sum_assignment = None
 
 
-@BBOX_ASSIGNERS.register_module()
+@BBOX_ASSIGNERS.register_module(force=True)
 class HungarianAssigner3DTrack(BaseAssigner):
     """Computes one-to-one matching between predictions and ground truth.
     This class computes an assignment between the targets and the predictions
diff --git a/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py b/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py
index 3b00003..a6f7d10 100755
--- a/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py
+++ b/projects/mmdet3d_plugin/core/bbox/coders/detr3d_track_coder.py
@@ -3,10 +3,12 @@ import torch
 from mmdet.core.bbox import BaseBBoxCoder
 from mmdet.core.bbox.builder import BBOX_CODERS
 from projects.mmdet3d_plugin.core.bbox.util import normalize_bbox, denormalize_bbox
-from mmdet3d.core import xywhr2xyxyr
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.core.bbox import xywhr2xyxyr
 from mmcv.ops import nms_bev
 
-@BBOX_CODERS.register_module()
+@BBOX_CODERS.register_module(force=True)
 class DETRTrack3DCoder(BaseBBoxCoder):
     """Bbox coder for DETR3D.
     Args:
diff --git a/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py b/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
index 614ee4c..bc836a0 100755
--- a/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
+++ b/projects/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
@@ -6,7 +6,7 @@ from projects.mmdet3d_plugin.core.bbox.util import denormalize_bbox
 import numpy as np
 
 
-@BBOX_CODERS.register_module()
+@BBOX_CODERS.register_module(force=True)
 class NMSFreeCoder(BaseBBoxCoder):
     """Bbox coder for NMS-free detector.
     Args:
diff --git a/projects/mmdet3d_plugin/core/bbox/match_costs/match_cost.py b/projects/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
index d73b7e0..8031308 100755
--- a/projects/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
+++ b/projects/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
@@ -3,7 +3,7 @@ from mmdet.core.bbox.match_costs.builder import MATCH_COST
 import torch.nn.functional as F
 
 
-@MATCH_COST.register_module()
+@MATCH_COST.register_module(force=True)
 class BBox3DL1Cost(object):
     """BBox3DL1Cost.
      Args:
@@ -28,7 +28,7 @@ class BBox3DL1Cost(object):
         return bbox_cost * self.weight
 
 
-@MATCH_COST.register_module()
+@MATCH_COST.register_module(force=True)
 class DiceCost(object):
     """IoUCost.
 
diff --git a/projects/mmdet3d_plugin/datasets/builder.py b/projects/mmdet3d_plugin/datasets/builder.py
index 0ad7a92..51634b6 100644
--- a/projects/mmdet3d_plugin/datasets/builder.py
+++ b/projects/mmdet3d_plugin/datasets/builder.py
@@ -121,7 +121,7 @@ OBJECTSAMPLERS = Registry('Object sampler')
 
 
 def custom_build_dataset(cfg, default_args=None):
-    from mmdet3d.datasets.dataset_wrappers import CBGSDataset
+    # from mmdet3d.datasets.dataset_wrappers import CBGSDataset
     from mmdet.datasets.dataset_wrappers import (ClassBalancedDataset,
                                                  ConcatDataset, RepeatDataset)
     if isinstance(cfg, (list, tuple)):
diff --git a/projects/mmdet3d_plugin/datasets/data_utils/trajectory_api.py b/projects/mmdet3d_plugin/datasets/data_utils/trajectory_api.py
index c812282..2b38215 100644
--- a/projects/mmdet3d_plugin/datasets/data_utils/trajectory_api.py
+++ b/projects/mmdet3d_plugin/datasets/data_utils/trajectory_api.py
@@ -2,7 +2,9 @@ import numpy as np
 from nuscenes.prediction import (PredictHelper,
                                  convert_local_coords_to_global,
                                  convert_global_coords_to_local)
-from mmdet3d.core.bbox import Box3DMode, Coord3DMode, LiDARInstance3DBoxes
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.core.bbox import Box3DMode, Coord3DMode, LiDARInstance3DBoxes
 from nuscenes.eval.common.utils import quaternion_yaw, Quaternion
 from mmcv.parallel import DataContainer as DC
 from mmdet.datasets.pipelines import to_tensor
diff --git a/projects/mmdet3d_plugin/datasets/eval_utils/nuscenes_eval_motion.py b/projects/mmdet3d_plugin/datasets/eval_utils/nuscenes_eval_motion.py
index 3af54f4..3176b63 100644
--- a/projects/mmdet3d_plugin/datasets/eval_utils/nuscenes_eval_motion.py
+++ b/projects/mmdet3d_plugin/datasets/eval_utils/nuscenes_eval_motion.py
@@ -39,7 +39,6 @@ from nuscenes.eval.detection.data_classes import DetectionConfig, DetectionMetri
     DetectionMetricDataList
 from nuscenes.eval.detection.render import summary_plot, class_pr_curve, dist_pr_curve, visualize_sample
 from nuscenes.eval.common.utils import quaternion_yaw, Quaternion
-from mmdet3d.core.bbox.iou_calculators import BboxOverlaps3D
 from IPython import embed
 import json
 from typing import Any
diff --git a/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py b/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py
index c1b9392..812ed82 100644
--- a/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py
+++ b/projects/mmdet3d_plugin/datasets/nuscenes_e2e_dataset.py
@@ -10,8 +10,10 @@ import torch
 import mmcv
 from mmdet.datasets import DATASETS
 from mmdet.datasets.pipelines import to_tensor
-from mmdet3d.datasets import NuScenesDataset
-from mmdet3d.core.bbox import LiDARInstance3DBoxes
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.datasets import NuScenesDataset
+from third_party.uniad_mmdet3d.core.bbox import LiDARInstance3DBoxes
 
 from os import path as osp
 from nuscenes.eval.common.utils import quaternion_yaw, Quaternion
@@ -34,7 +36,7 @@ from .data_utils.data_utils import lidar_nusc_box_to_global, obtain_map_info, ou
 from nuscenes.prediction import convert_local_coords_to_global
 
 
-@DATASETS.register_module()
+@DATASETS.register_module(force=True)
 class NuScenesE2EDataset(NuScenesDataset):
     r"""NuScenes E2E Dataset.
 
@@ -94,10 +96,12 @@ class NuScenesE2EDataset(NuScenesDataset):
                              dataroot=self.data_root, verbose=True)
 
         self.map_num_classes = 3
-        if canvas_size[0] == 50:
+        if canvas_size[0] == 50 or 100:
             self.thickness = 1
         elif canvas_size[0] == 200:
             self.thickness = 2
+        # elif canvas_size[0] == 100:
+        #     self.thickness = 2
         else:
             assert False
         self.angle_class = 36
@@ -981,8 +985,7 @@ class NuScenesE2EDataset(NuScenesDataset):
                  result_names=['pts_bbox'],
                  show=False,
                  out_dir=None,
-                 pipeline=None,
-                 planning_evaluation_strategy="uniad"):
+                 pipeline=None):
         """Evaluation in nuScenes protocol.
         Args:
             results (list[dict]): Testing results of the dataset.
@@ -1025,7 +1028,6 @@ class NuScenesE2EDataset(NuScenesDataset):
             if 'planning_results_computed' in results.keys():
                 planning_results_computed = results['planning_results_computed']
                 planning_tab = PrettyTable()
-                planning_tab.title = f"{planning_evaluation_strategy}'s definition planning metrics"
                 planning_tab.field_names = [
                     "metrics", "0.5s", "1.0s", "1.5s", "2.0s", "2.5s", "3.0s"]
                 for key in planning_results_computed.keys():
@@ -1033,14 +1035,7 @@ class NuScenesE2EDataset(NuScenesDataset):
                     row_value = []
                     row_value.append(key)
                     for i in range(len(value)):
-                        if planning_evaluation_strategy == "stp3":
-                            row_value.append("%.4f" % float(value[: i + 1].mean()))
-                        elif planning_evaluation_strategy == "uniad":
-                            row_value.append("%.4f" % float(value[i]))
-                        else:
-                            raise ValueError(
-                                "planning_evaluation_strategy should be uniad or spt3"
-                            )
+                        row_value.append('%.4f' % float(value[i]))
                     planning_tab.add_row(row_value)
                 print(planning_tab)
             results = results['bbox_results']  # get bbox_results
diff --git a/projects/mmdet3d_plugin/datasets/pipelines/formating.py b/projects/mmdet3d_plugin/datasets/pipelines/formating.py
index 5287852..b5ba9e7 100644
--- a/projects/mmdet3d_plugin/datasets/pipelines/formating.py
+++ b/projects/mmdet3d_plugin/datasets/pipelines/formating.py
@@ -2,14 +2,14 @@
 # Copyright (c) OpenMMLab. All rights reserved.
 import numpy as np
 from mmcv.parallel import DataContainer as DC
-
-from mmdet3d.core.bbox import BaseInstance3DBoxes
-from mmdet3d.core.points import BasePoints
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.datasets.pipelines import DefaultFormatBundle3D
 from mmdet.datasets.builder import PIPELINES
 from mmdet.datasets.pipelines import to_tensor
-from mmdet3d.datasets.pipelines import DefaultFormatBundle3D
 
-@PIPELINES.register_module()
+
+@PIPELINES.register_module(force=True)
 class CustomDefaultFormatBundle3D(DefaultFormatBundle3D):
     """Default formatting bundle.
     It simplifies the pipeline of formatting common fields for voxels,
diff --git a/projects/mmdet3d_plugin/datasets/pipelines/loading.py b/projects/mmdet3d_plugin/datasets/pipelines/loading.py
index 73d7ba4..7cda067 100644
--- a/projects/mmdet3d_plugin/datasets/pipelines/loading.py
+++ b/projects/mmdet3d_plugin/datasets/pipelines/loading.py
@@ -2,10 +2,12 @@ import numpy as np
 import mmcv
 from mmdet.datasets.builder import PIPELINES
 from einops import rearrange
-from mmdet3d.datasets.pipelines import LoadAnnotations3D
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.datasets.pipelines import LoadAnnotations3D
 import os
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class LoadMultiViewImageFromFilesInCeph(object):
     """Load multi channel images from a list of separate channel files.
 
@@ -82,7 +84,7 @@ class LoadMultiViewImageFromFilesInCeph(object):
         return repr_str
 
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class LoadAnnotations3D_E2E(LoadAnnotations3D):
     """Load Annotations3D.
 
diff --git a/projects/mmdet3d_plugin/datasets/pipelines/occflow_label.py b/projects/mmdet3d_plugin/datasets/pipelines/occflow_label.py
index 06c658a..e301186 100644
--- a/projects/mmdet3d_plugin/datasets/pipelines/occflow_label.py
+++ b/projects/mmdet3d_plugin/datasets/pipelines/occflow_label.py
@@ -7,7 +7,7 @@ from projects.mmdet3d_plugin.uniad.dense_heads.occ_head_plugin import calculate_
 from mmdet.datasets.builder import PIPELINES
 import os
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class GenerateOccFlowLabels(object):
     def __init__(self, grid_conf, ignore_index=255, only_vehicle=True, filter_invisible=True, deal_instance_255=False):
         self.grid_conf = grid_conf
diff --git a/projects/mmdet3d_plugin/datasets/pipelines/transform_3d.py b/projects/mmdet3d_plugin/datasets/pipelines/transform_3d.py
index c4e7d01..8df92e7 100755
--- a/projects/mmdet3d_plugin/datasets/pipelines/transform_3d.py
+++ b/projects/mmdet3d_plugin/datasets/pipelines/transform_3d.py
@@ -3,10 +3,12 @@ from numpy import random
 import mmcv
 from mmdet.datasets.builder import PIPELINES
 from mmcv.parallel import DataContainer as DC
-from mmdet3d.datasets.pipelines.transforms_3d import ObjectRangeFilter, ObjectNameFilter
-from mmdet3d.core.bbox import CameraInstance3DBoxes, DepthInstance3DBoxes, LiDARInstance3DBoxes
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.datasets.pipelines import ObjectRangeFilter, ObjectNameFilter
+from third_party.uniad_mmdet3d.core.bbox import CameraInstance3DBoxes, DepthInstance3DBoxes, LiDARInstance3DBoxes
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class PadMultiViewImage(object):
     """Pad the multi-view image.
     There are two padding modes: (1) pad to a fixed size and (2) pad to the
@@ -60,7 +62,7 @@ class PadMultiViewImage(object):
         return repr_str
 
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class NormalizeMultiviewImage(object):
     """Normalize the image.
     Added key is "img_norm_cfg".
@@ -97,7 +99,7 @@ class NormalizeMultiviewImage(object):
         return repr_str
 
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class PhotoMetricDistortionMultiViewImage:
     """Apply photometric distortion to image sequentially, every transformation
     is applied with a probability of 0.5. The position of random contrast is in
@@ -198,7 +200,7 @@ class PhotoMetricDistortionMultiViewImage:
 
 
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class CustomCollect3D(object):
     """Collect data from the loader relevant to the specific task.
     This is usually the last stage of the data loader pipeline. Typically keys
@@ -286,7 +288,7 @@ class CustomCollect3D(object):
 
 
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class RandomScaleImageMultiViewImage(object):
     """Random scale the image
     Args:
@@ -327,7 +329,7 @@ class RandomScaleImageMultiViewImage(object):
         repr_str += f'(size={self.scales}, '
         return repr_str
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class ObjectRangeFilterTrack(object):
     """Filter objects by the range.
     Args:
@@ -407,7 +409,7 @@ class ObjectRangeFilterTrack(object):
         repr_str += f'(point_cloud_range={self.pcd_range.tolist()})'
         return repr_str
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class ObjectNameFilterTrack(object):
     """Filter GT objects by their names.
     Args:
@@ -444,7 +446,7 @@ class ObjectNameFilterTrack(object):
         repr_str += f'(classes={self.classes})'
         return repr_str
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class CustomObjectRangeFilter(ObjectRangeFilter):
     def __call__(self, results):
         """Call function to filter objects by the range.
@@ -479,7 +481,7 @@ class CustomObjectRangeFilter(ObjectRangeFilter):
 
         return results
 
-@PIPELINES.register_module()
+@PIPELINES.register_module(force=True)
 class CustomObjectNameFilter(ObjectNameFilter):
     def __call__(self, results):
         """Call function to filter objects by their names.
diff --git a/projects/mmdet3d_plugin/datasets/samplers/distributed_sampler.py b/projects/mmdet3d_plugin/datasets/samplers/distributed_sampler.py
index 2913de9..d79cbc6 100644
--- a/projects/mmdet3d_plugin/datasets/samplers/distributed_sampler.py
+++ b/projects/mmdet3d_plugin/datasets/samplers/distributed_sampler.py
@@ -5,7 +5,7 @@ from torch.utils.data import DistributedSampler as _DistributedSampler
 from .sampler import SAMPLER
 
 
-@SAMPLER.register_module()
+@SAMPLER.register_module(force=True)
 class DistributedSampler(_DistributedSampler):
 
     def __init__(self,
diff --git a/projects/mmdet3d_plugin/datasets/samplers/group_sampler.py b/projects/mmdet3d_plugin/datasets/samplers/group_sampler.py
index 16c59e5..ce9ca83 100644
--- a/projects/mmdet3d_plugin/datasets/samplers/group_sampler.py
+++ b/projects/mmdet3d_plugin/datasets/samplers/group_sampler.py
@@ -11,7 +11,7 @@ import random
 from IPython import embed
 
 
-@SAMPLER.register_module()
+@SAMPLER.register_module(force=True)
 class DistributedGroupSampler(Sampler):
     """Sampler that restricts data loading to a subset of the dataset.
     It is especially useful in conjunction with
diff --git a/projects/mmdet3d_plugin/losses/dice_loss.py b/projects/mmdet3d_plugin/losses/dice_loss.py
index 3cb635f..19761cb 100644
--- a/projects/mmdet3d_plugin/losses/dice_loss.py
+++ b/projects/mmdet3d_plugin/losses/dice_loss.py
@@ -21,7 +21,7 @@ def dice_loss(input, target,mask=None,eps=0.001):
     d = (2 * a) / (b + c)
     return 1 - d
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class DiceLoss(nn.Module):
 
     def __init__(self, eps=1e-6, reduction='mean', loss_weight=1.0):
diff --git a/projects/mmdet3d_plugin/losses/mtp_loss.py b/projects/mmdet3d_plugin/losses/mtp_loss.py
index e6e5234..b0ad95f 100644
--- a/projects/mmdet3d_plugin/losses/mtp_loss.py
+++ b/projects/mmdet3d_plugin/losses/mtp_loss.py
@@ -12,7 +12,7 @@ import math
 
 from mmdet.models import LOSSES
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class MTPLoss(nn.Module):
     """
     MTP loss modified to include variances. Uses MSE for mode selection.
diff --git a/projects/mmdet3d_plugin/losses/occflow_loss.py b/projects/mmdet3d_plugin/losses/occflow_loss.py
index d9ae64b..dda7253 100644
--- a/projects/mmdet3d_plugin/losses/occflow_loss.py
+++ b/projects/mmdet3d_plugin/losses/occflow_loss.py
@@ -11,7 +11,7 @@ from einops import rearrange
 from mmdet.models.builder import LOSSES
 from mmdet.models.losses.utils import weight_reduce_loss
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class FieryBinarySegmentationLoss(nn.Module):
     def __init__(self, use_top_k=False, top_k_ratio=1.0, future_discount=1.0, loss_weight=1.0, ignore_index=255):
         super().__init__()
@@ -137,7 +137,7 @@ def dice_loss(pred,
     loss = weight_reduce_loss(loss, weight, reduction, avg_factor)
     return loss
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class DiceLossWithMasks(nn.Module):
     def __init__(self,
                  use_sigmoid=True,
diff --git a/projects/mmdet3d_plugin/losses/planning_loss.py b/projects/mmdet3d_plugin/losses/planning_loss.py
index 6d47070..dc13b01 100644
--- a/projects/mmdet3d_plugin/losses/planning_loss.py
+++ b/projects/mmdet3d_plugin/losses/planning_loss.py
@@ -12,7 +12,7 @@ import pickle
 from mmdet.models import LOSSES
 
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class PlanningLoss(nn.Module):
     def __init__(self, loss_type='L2'):
         super(PlanningLoss, self).__init__()
@@ -26,7 +26,7 @@ class PlanningLoss(nn.Module):
         return torch.sum(err * mask)/(torch.sum(mask) + 1e-5)
 
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class CollisionLoss(nn.Module):
     def __init__(self, delta=0.5, weight=1.0):
         super(CollisionLoss, self).__init__()
diff --git a/projects/mmdet3d_plugin/losses/track_loss.py b/projects/mmdet3d_plugin/losses/track_loss.py
index 549c5ae..ec18805 100644
--- a/projects/mmdet3d_plugin/losses/track_loss.py
+++ b/projects/mmdet3d_plugin/losses/track_loss.py
@@ -20,7 +20,9 @@ from mmdet.core import build_assigner
 from mmdet.models import build_loss
 from mmdet.models.builder import LOSSES
 from mmdet.core import reduce_mean
-from mmdet3d.core.bbox.iou_calculators.iou3d_calculator import (
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.core.bbox.iou_calculators.iou3d_calculator import (
     bbox_overlaps_nearest_3d as iou_3d, )
 from projects.mmdet3d_plugin.core.bbox.util import denormalize_bbox
 
@@ -58,7 +60,7 @@ def accuracy(output, target, topk=(1, )):
     return res
 
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class ClipMatcher(nn.Module):
     def __init__(
             self,
diff --git a/projects/mmdet3d_plugin/losses/traj_loss.py b/projects/mmdet3d_plugin/losses/traj_loss.py
index 87b26ca..95860f9 100644
--- a/projects/mmdet3d_plugin/losses/traj_loss.py
+++ b/projects/mmdet3d_plugin/losses/traj_loss.py
@@ -12,7 +12,7 @@ from typing import Tuple
 
 from mmdet.models import LOSSES
 
-@LOSSES.register_module()
+@LOSSES.register_module(force=True)
 class TrajLoss(nn.Module):
     """
     MTP loss modified to include variances. Uses MSE for mode selection.
diff --git a/projects/mmdet3d_plugin/models/backbones/vovnet.py b/projects/mmdet3d_plugin/models/backbones/vovnet.py
index 879d186..093ad6f 100755
--- a/projects/mmdet3d_plugin/models/backbones/vovnet.py
+++ b/projects/mmdet3d_plugin/models/backbones/vovnet.py
@@ -265,7 +265,7 @@ class _OSA_stage(nn.Sequential):
             )
 
 
-@BACKBONES.register_module()
+@BACKBONES.register_module(force=True)
 class VoVNet(BaseModule):
     def __init__(self, spec_name, input_ch=3, out_features=None, 
                  frozen_stages=-1, norm_eval=True, pretrained=None, init_cfg=None):
diff --git a/projects/mmdet3d_plugin/models/hooks/hooks.py b/projects/mmdet3d_plugin/models/hooks/hooks.py
index 56ff7fd..32ed71a 100644
--- a/projects/mmdet3d_plugin/models/hooks/hooks.py
+++ b/projects/mmdet3d_plugin/models/hooks/hooks.py
@@ -2,7 +2,7 @@ from mmcv.runner.hooks.hook import HOOKS, Hook
 from projects.mmdet3d_plugin.models.utils import run_time
 
 
-@HOOKS.register_module()
+@HOOKS.register_module(force=True)
 class GradChecker(Hook):
 
     def after_train_iter(self, runner):
diff --git a/projects/mmdet3d_plugin/models/opt/adamw.py b/projects/mmdet3d_plugin/models/opt/adamw.py
index c890aea..64519d1 100644
--- a/projects/mmdet3d_plugin/models/opt/adamw.py
+++ b/projects/mmdet3d_plugin/models/opt/adamw.py
@@ -7,7 +7,7 @@ import torch
 from torch.optim.optimizer import Optimizer
 from mmcv.runner.optimizer.builder import OPTIMIZERS
 
-@OPTIMIZERS.register_module()
+@OPTIMIZERS.register_module(force=True)
 class AdamW2(Optimizer):
     r"""Implements AdamW algorithm. Solve the bug of torch 1.8
 
diff --git a/projects/mmdet3d_plugin/uniad/apis/test.py b/projects/mmdet3d_plugin/uniad/apis/test.py
index 72445e8..ea53cc5 100644
--- a/projects/mmdet3d_plugin/uniad/apis/test.py
+++ b/projects/mmdet3d_plugin/uniad/apis/test.py
@@ -60,8 +60,7 @@ def custom_multi_gpu_test(model, data_loader, tmpdir=None, gpu_collect=False):
                 and model.module.with_occ_head
     if eval_occ:
         # 30mx30m, 100mx100m at 50cm resolution
-        EVALUATION_RANGES = {'30x30': (70, 130),
-                            '100x100': (0, 200)}
+        EVALUATION_RANGES = {'8x8': (17, 33), '25x25': (0, 50)}
         n_classes = 2
         iou_metrics = {}
         for key in EVALUATION_RANGES.keys():
@@ -74,7 +73,11 @@ def custom_multi_gpu_test(model, data_loader, tmpdir=None, gpu_collect=False):
     eval_planning =  hasattr(model.module, 'with_planning_head') \
                       and model.module.with_planning_head
     if eval_planning:
-        planning_metrics = PlanningMetric().cuda()
+        planning_metrics = PlanningMetric(conf={
+            'xbound': [-12.5, 12.5, 0.5],
+            'ybound': [-12.5, 12.5, 0.5],
+            'zbound': [-10.0, 10.0, 20.0],
+        }).cuda()
         
     bbox_results = []
     mask_results = []
@@ -99,7 +102,8 @@ def custom_multi_gpu_test(model, data_loader, tmpdir=None, gpu_collect=False):
                 result[0]['planning_traj'] = result[0]['planning']['result_planning']['sdc_traj']
                 result[0]['planning_traj_gt'] = result[0]['planning']['planning_gt']['sdc_planning']
                 result[0]['command'] = result[0]['planning']['planning_gt']['command']
-                planning_metrics(pred_sdc_traj[:, :6, :2], sdc_planning[0][0,:, :6, :2], sdc_planning_mask[0][0,:, :6, :2], segmentation[0][:, [1,2,3,4,5,6]])
+                planning_metrics(pred_sdc_traj[:, :6, :2], sdc_planning[0][0,:, :6, :2], 
+                                 sdc_planning_mask[0][0,:, :6, :2], segmentation[0][:, [1,2,3,4,5,6]])
 
             # Eval Occ
             if eval_occ:
diff --git a/projects/mmdet3d_plugin/uniad/apis/train.py b/projects/mmdet3d_plugin/uniad/apis/train.py
index f44c9d8..a12c4cb 100644
--- a/projects/mmdet3d_plugin/uniad/apis/train.py
+++ b/projects/mmdet3d_plugin/uniad/apis/train.py
@@ -1,5 +1,5 @@
 from .mmdet_train import custom_train_detector
-from mmseg.apis import train_segmentor
+# from mmseg.apis import train_segmentor
 from mmdet.apis import train_detector
 
 def custom_train_model(model,
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py
index dd3612a..a2842c8 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/motion_head.py
@@ -18,7 +18,7 @@ from .motion_head_plugin.motion_utils import nonlinear_smoother
 from .motion_head_plugin.base_motion_head import BaseMotionHead
 
 
-@HEADS.register_module()
+@HEADS.register_module(force=True)
 class MotionHead(BaseMotionHead):
     """
     MotionHead module for a neural network, which predicts motion trajectories and is used in an autonomous driving task.
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/modules.py b/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/modules.py
index f576335..bc1c0de 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/modules.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/modules.py
@@ -16,7 +16,7 @@ from projects.mmdet3d_plugin.models.utils.functional import (
 )
 
 
-@TRANSFORMER_LAYER_SEQUENCE.register_module()
+@TRANSFORMER_LAYER_SEQUENCE.register_module(force=True)
 class MotionTransformerDecoder(BaseModule):
     """Implements the decoder in DETR3D transformer.
     Args:
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/motion_deformable_attn.py b/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/motion_deformable_attn.py
index 9aaee7e..8f4be7a 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/motion_deformable_attn.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/motion_head_plugin/motion_deformable_attn.py
@@ -21,7 +21,7 @@ from mmcv.utils import ConfigDict, deprecated_api_warning
 from projects.mmdet3d_plugin.uniad.modules.multi_scale_deformable_attn_function import MultiScaleDeformableAttnFunction_fp32
 
 
-@TRANSFORMER_LAYER.register_module()
+@TRANSFORMER_LAYER.register_module(force=True)
 class MotionTransformerAttentionLayer(BaseModule):
     """Base `TransformerLayer` for vision transformer.
     It can be built from `mmcv.ConfigDict` and support more flexible
@@ -239,7 +239,7 @@ class MotionTransformerAttentionLayer(BaseModule):
 
         return query
 
-@ATTENTION.register_module()
+@ATTENTION.register_module(force=True)
 class MotionDeformableAttention(BaseModule):
     """An attention module used in Deformable-Detr.
 
@@ -486,7 +486,7 @@ class MotionDeformableAttention(BaseModule):
         out = torch.stack([torch.stack([cy, -sy]), torch.stack([sy, cy])]).permute([2,0,1])
         return out
 
-@ATTENTION.register_module()
+@ATTENTION.register_module(force=True)
 class CustomModeMultiheadAttention(BaseModule):
     """A wrapper for ``torch.nn.MultiheadAttention``.
     This module implements MultiheadAttention with identity connection,
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/occ_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/occ_head.py
index ffa5e21..687893d 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/occ_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/occ_head.py
@@ -19,7 +19,7 @@ from .occ_head_plugin import MLP, BevFeatureSlicer, SimpleConv2d, CVT_Decoder, B
 def _get_clones(module, N):
     return nn.ModuleList([copy.deepcopy(module) for i in range(N)])
 
-@HEADS.register_module()
+@HEADS.register_module(force=True)
 class OccHead(BaseModule):
     def __init__(self, 
                  # General
@@ -35,6 +35,7 @@ class OccHead(BaseModule):
                  bev_emb_dim=256,
                  bev_proj_dim=64,
                  bev_proj_nlayers=1,
+                 bevslicer=True,
 
                  # Query
                  query_dim=256,
@@ -75,6 +76,7 @@ class OccHead(BaseModule):
             'zbound': [-10.0, 10.0, 20.0],
         }
         self.bev_sampler =  BevFeatureSlicer(bevformer_bev_conf, grid_conf)
+        self.bevslicer = bevslicer
         
         self.bev_size = bev_size
         self.bev_proj_dim = bev_proj_dim
@@ -196,9 +198,12 @@ class OccHead(BaseModule):
         return attn_mask, upsampled_mask_pred, ins_embed
 
     def forward(self, x, ins_query):
-        base_state = rearrange(x, '(h w) b d -> b d h w', h=self.bev_size[0])
+        # base_state = rearrange(x, '(h w) b d -> b d h w', h=self.bev_size[0])
+        _, b,d=x.shape
+        base_state = x.permute(1,2,0).view(b,d,self.bev_size[0],self.bev_size[1])
 
-        base_state = self.bev_sampler(base_state)
+        if self.bevslicer:
+            base_state = self.bev_sampler(base_state)
         base_state = self.bev_light_proj(base_state)
         base_state = self.base_downscale(base_state)
         base_ins_query = ins_query
@@ -228,8 +233,11 @@ class OccHead(BaseModule):
             mask_preds.append(mask_pred)  # /1
             temporal_embed_for_mask_attn.append(cur_ins_emb_for_mask_attn)
 
-            cur_state = rearrange(cur_state, 'b c h w -> (h w) b c')
-            cur_ins_query = rearrange(cur_ins_query, 'b q c -> q b c')
+            # cur_state = rearrange(cur_state, 'b c h w -> (h w) b c')
+            b,c,h,w=cur_state.shape
+            cur_state = cur_state.view(b,c,h*w).permute(2,0,1)
+            # cur_ins_query = rearrange(cur_ins_query, 'b q c -> q b c')
+            cur_ins_query=cur_ins_query.permute(1,0,2)
 
             for j in range(n_trans_layer_each_block):
                 trans_layer_ind = i * n_trans_layer_each_block + j
@@ -245,7 +253,10 @@ class OccHead(BaseModule):
                     key_padding_mask=None
                 )  # out size: [h'*w', b, c]
 
-            cur_state = rearrange(cur_state, '(h w) b c -> b c h w', h=self.bev_size[0]//8)
+            # cur_state = rearrange(cur_state, '(h w) b c -> b c h w', h=self.bev_size[0]//8)
+            cur_state_h = int(cur_state.shape[0]**0.5)
+            _, b, c = cur_state.shape
+            cur_state = cur_state.permute(1,2,0).view(b,c,cur_state_h,cur_state_h)
             
             # Upscale to /4
             cur_state = self.upsample_adds[i](cur_state, last_state)
@@ -261,6 +272,12 @@ class OccHead(BaseModule):
 
         # Decode future states to larger resolution
         future_states = self.dense_decoder(future_states)
+        future_states = F.interpolate(
+                        future_states,
+                        (int(future_states.shape[-3]), int(self.bev_size[-2]), int(self.bev_size[-1])),
+                        mode='trilinear',
+                        align_corners=False
+                        )
         ins_occ_query = self.query_to_occ_feat(ins_query)    # [b, t, q, query_out_dim]
         
         # Generate final outputs
@@ -449,7 +466,6 @@ class OccHead(BaseModule):
                 predict_instance_segmentation_and_trajectories(seg_out, pred_ins_sigmoid)  # bg is 0, fg starts with 1, consecutive
             
             out_dict['ins_seg_out'] = pred_consistent_instance_seg  # [1, 5, 200, 200]
-
         return out_dict
 
     def get_ins_seg_gt(self, gt_instance):
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/occ_head_plugin/modules.py b/projects/mmdet3d_plugin/uniad/dense_heads/occ_head_plugin/modules.py
index 2561f81..9a74520 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/occ_head_plugin/modules.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/occ_head_plugin/modules.py
@@ -225,6 +225,12 @@ class UpsamplingAdd(nn.Module):
 
     def forward(self, x, x_skip):
         x = self.upsample_layer(x)
+        x = F.interpolate(
+                        x,
+                        (int(x_skip.shape[-2]), int(x_skip.shape[-1])),
+                        mode='bilinear',
+                        align_corners=False
+                        )
         return x + x_skip
 
 class Interpolate(nn.Module):
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py
index 83363cf..6d8b714 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/panseg_head.py
@@ -20,7 +20,7 @@ from mmdet.core import (bbox_cxcywh_to_xyxy, bbox_xyxy_to_cxcywh,
 from mmdet.models.utils import build_transformer
 from .seg_head_plugin import SegDETRHead, IOU
 
-@HEADS.register_module()
+@HEADS.register_module(force=True)
 class PansegformerHead(SegDETRHead):
     """
     Head of Panoptic SegFormer
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/planning_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/planning_head.py
index 6eb5a56..4984f04 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/planning_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/planning_head.py
@@ -13,7 +13,7 @@ from .planning_head_plugin import CollisionNonlinearOptimizer
 import numpy as np
 import copy
 
-@HEADS.register_module()
+@HEADS.register_module(force=True)
 class PlanningHeadSingleMode(nn.Module):
     def __init__(self,
                  bev_h=200,
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/planning_head_plugin/planning_metrics.py b/projects/mmdet3d_plugin/uniad/dense_heads/planning_head_plugin/planning_metrics.py
index fdcf079..dae9f09 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/planning_head_plugin/planning_metrics.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/planning_head_plugin/planning_metrics.py
@@ -17,15 +17,20 @@ class PlanningMetric(Metric):
         self,
         n_future=6,
         compute_on_step: bool = False,
+        conf = {
+            'xbound': [-50.0, 50.0, 0.5],
+            'ybound': [-50.0, 50.0, 0.5],
+            'zbound': [-10.0, 10.0, 20.0],
+        },
     ):
         super().__init__(compute_on_step=compute_on_step)
-        dx, bx, _ = gen_dx_bx([-50.0, 50.0, 0.5], [-50.0, 50.0, 0.5], [-10.0, 10.0, 20.0])
+        dx, bx, _ = gen_dx_bx(conf['xbound'], conf['ybound'], conf['zbound'])
         dx, bx = dx[:2], bx[:2]
         self.dx = nn.Parameter(dx, requires_grad=False)
         self.bx = nn.Parameter(bx, requires_grad=False)
 
         _, _, self.bev_dimension = calculate_birds_eye_view_parameters(
-            [-50.0, 50.0, 0.5], [-50.0, 50.0, 0.5], [-10.0, 10.0, 20.0]
+            conf['xbound'], conf['ybound'], conf['zbound']
         )
         self.bev_dimension = self.bev_dimension.numpy()
 
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_assigner.py b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_assigner.py
index ebfd3b8..8397e0f 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_assigner.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_assigner.py
@@ -165,7 +165,7 @@ class SamplingResult_segformer(util_mixins.NiceRepr):
         return self
 
 
-@BBOX_SAMPLERS.register_module()
+@BBOX_SAMPLERS.register_module(force=True)
 class PseudoSampler_segformer(BaseSampler):
     """A pseudo sampler that does not do sampling actually."""
 
@@ -201,7 +201,7 @@ class PseudoSampler_segformer(BaseSampler):
         return sampling_result
 
 
-@BBOX_ASSIGNERS.register_module()
+@BBOX_ASSIGNERS.register_module(force=True)
 class HungarianAssigner_filter(BaseAssigner):
     """
     """
@@ -300,7 +300,7 @@ class HungarianAssigner_filter(BaseAssigner):
             
 
 
-@BBOX_ASSIGNERS.register_module()
+@BBOX_ASSIGNERS.register_module(force=True)
 class HungarianAssigner_multi_info(BaseAssigner):
     """Computes one-to-one matching between predictions and ground truth.
 
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py
index f695dd6..0ae9ec9 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_deformable_transformer.py
@@ -24,7 +24,7 @@ from einops import rearrange, repeat
 from einops.layers.torch import Rearrange
 
 # Copy-paste from defromable detr in mmdet.
-@TRANSFORMER.register_module()
+@TRANSFORMER.register_module(force=True)
 class SegDeformableTransformer(Transformer):
     """Implements the DeformableDETR transformer.
 
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_detr_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_detr_head.py
index 7093e97..1afda0c 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_detr_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_detr_head.py
@@ -14,7 +14,7 @@ from mmdet.models.dense_heads.anchor_free_head import AnchorFreeHead
 from mmdet.models.builder import HEADS, build_loss
 
 
-@HEADS.register_module()
+@HEADS.register_module(force=True)
 class SegDETRHead(
         AnchorFreeHead
 ):  # I modify DETRHead to make it to support panoptic segmentation
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_mask_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_mask_head.py
index 64f976e..8c25a15 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_mask_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/seg_head_plugin/seg_mask_head.py
@@ -306,7 +306,7 @@ class DropPath(nn.Module):
         return drop_path(x, self.drop_prob, self.training)
 
 
-@TRANSFORMER.register_module()
+@TRANSFORMER.register_module(force=True)
 class SegMaskHead(nn.Module):
     def __init__(self,
                  cfg=None,
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/track_head.py b/projects/mmdet3d_plugin/uniad/dense_heads/track_head.py
index 1552735..cef8917 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/track_head.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/track_head.py
@@ -16,12 +16,12 @@ from mmdet.core import (multi_apply, multi_apply, reduce_mean)
 from mmdet.models.utils.transformer import inverse_sigmoid
 from mmdet.models import HEADS
 from mmdet.models.dense_heads import DETRHead
-from mmdet3d.core.bbox.coders import build_bbox_coder
+from mmdet.core.bbox import build_bbox_coder
 from projects.mmdet3d_plugin.core.bbox.util import normalize_bbox
 from mmcv.runner import force_fp32, auto_fp16
 
 
-@HEADS.register_module()
+@HEADS.register_module(force=True)
 class BEVFormerTrackHead(DETRHead):
     """Head of Detr3D.
     Args:
diff --git a/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py b/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py
index 55e45f5..0a7f7fa 100644
--- a/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py
+++ b/projects/mmdet3d_plugin/uniad/dense_heads/track_head_plugin/tracker.py
@@ -1,5 +1,7 @@
 from .track_instance import Instances
-from mmdet3d.core.bbox.iou_calculators.iou3d_calculator import (
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.core.bbox.iou_calculators.iou3d_calculator import (
     bbox_overlaps_nearest_3d as iou_3d, )
 from projects.mmdet3d_plugin.core.bbox.util import denormalize_bbox
 
diff --git a/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py b/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py
index 78a4a87..fd319c9 100644
--- a/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py
+++ b/projects/mmdet3d_plugin/uniad/detectors/uniad_e2e.py
@@ -13,7 +13,7 @@ from ..dense_heads.seg_head_plugin import IOU
 from .uniad_track import UniADTrack
 from mmdet.models.builder import build_head
 
-@DETECTORS.register_module()
+@DETECTORS.register_module(force=True)
 class UniAD(UniADTrack):
     """
     UniAD: Unifying Detection, Tracking, Segmentation, Motion Forecasting, Occupancy Prediction and Planning for Autonomous Driving
@@ -31,6 +31,8 @@ class UniAD(UniADTrack):
             occ=1.0,
             planning=1.0
         ),
+        upsample_if_tiny=True,
+        upsample_scale_factor=4,
         **kwargs,
     ):
         super(UniAD, self).__init__(**kwargs)
@@ -44,6 +46,8 @@ class UniAD(UniADTrack):
             self.planning_head = build_head(planning_head)
         
         self.task_loss_weight = task_loss_weight
+        self.upsample_if_tiny = upsample_if_tiny
+        self.upsample_scale_factor = upsample_scale_factor
         assert set(task_loss_weight.keys()) == \
                {'track', 'occ', 'motion', 'map', 'planning'}
 
@@ -166,7 +170,8 @@ class UniAD(UniADTrack):
         losses.update(losses_track)
         
         # Upsample bev for tiny version
-        outs_track = self.upsample_bev_if_tiny(outs_track)
+        if self.upsample_if_tiny:
+            outs_track = self.upsample_bev_if_tiny(outs_track, scale_factor=self.upsample_scale_factor)
 
         bev_embed = outs_track["bev_embed"]
         bev_pos  = outs_track["bev_pos"]
@@ -254,6 +259,9 @@ class UniAD(UniADTrack):
                     ):
         """Test function
         """
+        img_metas = img_metas[0].data
+        img = img[0].data
+
         for var, name in [(img_metas, 'img_metas')]:
             if not isinstance(var, list):
                 raise TypeError('{} must be a list, but got {}'.format(
@@ -284,7 +292,7 @@ class UniAD(UniADTrack):
         self.prev_frame_info['prev_pos'] = tmp_pos
         self.prev_frame_info['prev_angle'] = tmp_angle
 
-        img = img[0]
+        img = img[0].cuda()
         img_metas = img_metas[0]
         timestamp = timestamp[0] if timestamp is not None else None
 
@@ -292,7 +300,8 @@ class UniAD(UniADTrack):
         result_track = self.simple_test_track(img, l2g_t, l2g_r_mat, img_metas, timestamp)
 
         # Upsample bev for tiny model        
-        result_track[0] = self.upsample_bev_if_tiny(result_track[0])
+        if self.upsample_if_tiny:
+            result_track[0] = self.upsample_bev_if_tiny(result_track[0], scale_factor=self.upsample_scale_factor)
         
         bev_embed = result_track[0]["bev_embed"]
 
diff --git a/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py b/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py
index 577ae38..439edf7 100644
--- a/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py
+++ b/projects/mmdet3d_plugin/uniad/detectors/uniad_track.py
@@ -8,9 +8,10 @@ import torch
 import torch.nn as nn
 from mmcv.runner import auto_fp16
 from mmdet.models import DETECTORS
-from mmdet3d.core import bbox3d2result
-from mmdet3d.core.bbox.coders import build_bbox_coder
-from mmdet3d.models.detectors.mvx_two_stage import MVXTwoStageDetector
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from mmdet.core.bbox import build_bbox_coder
+from third_party.uniad_mmdet3d.models.detectors.mvx_two_stage import MVXTwoStageDetector
 from projects.mmdet3d_plugin.models.utils.grid_mask import GridMask
 import copy
 import math
@@ -20,7 +21,7 @@ from einops import rearrange
 from mmdet.models.utils.transformer import inverse_sigmoid
 from ..dense_heads.track_head_plugin import MemoryBank, QueryInteractionModule, Instances, RuntimeTrackerBase
 
-@DETECTORS.register_module()
+@DETECTORS.register_module(force=True)
 class UniADTrack(MVXTwoStageDetector):
     """UniAD tracking part
     """
@@ -580,9 +581,9 @@ class UniADTrack(MVXTwoStageDetector):
         losses = self.criterion.losses_dict
         return losses, out
 
-    def upsample_bev_if_tiny(self, outs_track):
+    def upsample_bev_if_tiny(self, outs_track, scale_factor=4):
         if outs_track["bev_embed"].size(0) == 100 * 100:
-            # For tiny model
+            # For small model
             # bev_emb
             bev_embed = outs_track["bev_embed"] # [10000, 1, 256]
             dim, _, _ = bev_embed.size()
@@ -614,6 +615,40 @@ class UniADTrack(MVXTwoStageDetector):
             bev_pos  = outs_track["bev_pos"]  # [1, 256, 100, 100]
             bev_pos = nn.Upsample(scale_factor=2)(bev_pos)  # [1, 256, 200, 200]
             outs_track["bev_pos"] = bev_pos
+
+        elif outs_track["bev_embed"].size(0) == 50 * 50:
+            # For tiny model
+            # bev_emb
+            bev_embed = outs_track["bev_embed"] # [2500, 1, 256]
+            dim, _, _ = bev_embed.size()
+            w = h = int(math.sqrt(dim))
+            assert h == w == 50
+
+            bev_embed = rearrange(bev_embed, '(h w) b c -> b c h w', h=h, w=w)  # [1, 256, 50, 50]
+            bev_embed = nn.Upsample(scale_factor=scale_factor)(bev_embed)  # [1, 256, 200, 200]
+            bev_embed = rearrange(bev_embed, 'b c h w -> (h w) b c')
+            outs_track["bev_embed"] = bev_embed
+
+            # prev_bev
+            prev_bev = outs_track.get("prev_bev", None)
+            if prev_bev is not None:
+                if self.training:
+                    #  [1, 2500, 256]
+                    prev_bev = rearrange(prev_bev, 'b (h w) c -> b c h w', h=h, w=w)
+                    prev_bev = nn.Upsample(scale_factor=scale_factor)(prev_bev)  # [1, 256, 200, 200]
+                    prev_bev = rearrange(prev_bev, 'b c h w -> b (h w) c')
+                    outs_track["prev_bev"] = prev_bev
+                else:
+                    #  [2500, 1, 256]
+                    prev_bev = rearrange(prev_bev, '(h w) b c -> b c h w', h=h, w=w)
+                    prev_bev = nn.Upsample(scale_factor=scale_factor)(prev_bev)  # [1, 256, 200, 200]
+                    prev_bev = rearrange(prev_bev, 'b c h w -> (h w) b c')
+                    outs_track["prev_bev"] = prev_bev
+
+            # bev_pos
+            bev_pos  = outs_track["bev_pos"]  # [1, 256, 50, 50]
+            bev_pos = nn.Upsample(scale_factor=scale_factor)(bev_pos)  # [1, 256, 200, 200]
+            outs_track["bev_pos"] = bev_pos
         return outs_track
 
 
diff --git a/projects/mmdet3d_plugin/uniad/hooks/custom_hooks.py b/projects/mmdet3d_plugin/uniad/hooks/custom_hooks.py
index 8238993..3d935b3 100644
--- a/projects/mmdet3d_plugin/uniad/hooks/custom_hooks.py
+++ b/projects/mmdet3d_plugin/uniad/hooks/custom_hooks.py
@@ -1,7 +1,7 @@
 from mmcv.runner.hooks.hook import HOOKS, Hook
 
 
-@HOOKS.register_module()
+@HOOKS.register_module(force=True)
 class TransferWeight(Hook):
     
     def __init__(self, every_n_inters=1):
diff --git a/projects/mmdet3d_plugin/uniad/modules/custom_base_transformer_layer.py b/projects/mmdet3d_plugin/uniad/modules/custom_base_transformer_layer.py
index 8b7e614..3bb5bfb 100644
--- a/projects/mmdet3d_plugin/uniad/modules/custom_base_transformer_layer.py
+++ b/projects/mmdet3d_plugin/uniad/modules/custom_base_transformer_layer.py
@@ -17,7 +17,7 @@ from mmcv.cnn.bricks.registry import TRANSFORMER_LAYER
 from mmcv.cnn.bricks.transformer import build_feedforward_network, build_attention
 
 
-@TRANSFORMER_LAYER.register_module()
+@TRANSFORMER_LAYER.register_module(force=True)
 class MyCustomBaseTransformerLayer(BaseModule):
     """Base `TransformerLayer` for vision transformer.
     It can be built from `mmcv.ConfigDict` and support more flexible
diff --git a/projects/mmdet3d_plugin/uniad/modules/decoder.py b/projects/mmdet3d_plugin/uniad/modules/decoder.py
index 33024f8..99a9039 100644
--- a/projects/mmdet3d_plugin/uniad/modules/decoder.py
+++ b/projects/mmdet3d_plugin/uniad/modules/decoder.py
@@ -49,7 +49,7 @@ def inverse_sigmoid(x, eps=1e-5):
     return torch.log(x1 / x2)
 
 
-@TRANSFORMER_LAYER_SEQUENCE.register_module()
+@TRANSFORMER_LAYER_SEQUENCE.register_module(force=True)
 class DetectionTransformerDecoder(TransformerLayerSequence):
     """Implements the decoder in DETR3D transformer.
     Args:
@@ -129,7 +129,7 @@ class DetectionTransformerDecoder(TransformerLayerSequence):
         return output, reference_points
 
 
-@ATTENTION.register_module()
+@ATTENTION.register_module(force=True)
 class CustomMSDeformableAttention(BaseModule):
     """An attention module used in Deformable-Detr.
 
diff --git a/projects/mmdet3d_plugin/uniad/modules/encoder.py b/projects/mmdet3d_plugin/uniad/modules/encoder.py
index 6875233..f5565ac 100644
--- a/projects/mmdet3d_plugin/uniad/modules/encoder.py
+++ b/projects/mmdet3d_plugin/uniad/modules/encoder.py
@@ -23,7 +23,7 @@ ext_module = ext_loader.load_ext(
     '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])
 
 
-@TRANSFORMER_LAYER_SEQUENCE.register_module()
+@TRANSFORMER_LAYER_SEQUENCE.register_module(force=True)
 class BEVFormerEncoder(TransformerLayerSequence):
 
     """
@@ -235,7 +235,7 @@ class BEVFormerEncoder(TransformerLayerSequence):
         return output
 
 
-@TRANSFORMER_LAYER.register_module()
+@TRANSFORMER_LAYER.register_module(force=True)
 class BEVFormerLayer(MyCustomBaseTransformerLayer):
     """Implements decoder layer in DETR transformer.
     Args:
diff --git a/projects/mmdet3d_plugin/uniad/modules/spatial_cross_attention.py b/projects/mmdet3d_plugin/uniad/modules/spatial_cross_attention.py
index 77dfa91..747e666 100644
--- a/projects/mmdet3d_plugin/uniad/modules/spatial_cross_attention.py
+++ b/projects/mmdet3d_plugin/uniad/modules/spatial_cross_attention.py
@@ -27,7 +27,7 @@ ext_module = ext_loader.load_ext(
     '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])
 
 
-@ATTENTION.register_module()
+@ATTENTION.register_module(force=True)
 class SpatialCrossAttention(BaseModule):
     """An attention module used in BEVFormer.
     Args:
@@ -174,7 +174,7 @@ class SpatialCrossAttention(BaseModule):
         return self.dropout(slots) + inp_residual
 
 
-@ATTENTION.register_module()
+@ATTENTION.register_module(force=True)
 class MSDeformableAttention3D(BaseModule):
     """An attention module used in BEVFormer based on Deformable-Detr.
     `Deformable DETR: Deformable Transformers for End-to-End Object Detection.
diff --git a/projects/mmdet3d_plugin/uniad/modules/temporal_self_attention.py b/projects/mmdet3d_plugin/uniad/modules/temporal_self_attention.py
index f846b4b..5265dc1 100644
--- a/projects/mmdet3d_plugin/uniad/modules/temporal_self_attention.py
+++ b/projects/mmdet3d_plugin/uniad/modules/temporal_self_attention.py
@@ -21,7 +21,7 @@ ext_module = ext_loader.load_ext(
     '_ext', ['ms_deform_attn_backward', 'ms_deform_attn_forward'])
 
 
-@ATTENTION.register_module()
+@ATTENTION.register_module(force=True)
 class TemporalSelfAttention(BaseModule):
     """An attention module used in BEVFormer based on Deformable-Detr.
 
diff --git a/projects/mmdet3d_plugin/uniad/modules/transformer.py b/projects/mmdet3d_plugin/uniad/modules/transformer.py
index bb5fae8..85516ac 100644
--- a/projects/mmdet3d_plugin/uniad/modules/transformer.py
+++ b/projects/mmdet3d_plugin/uniad/modules/transformer.py
@@ -20,7 +20,7 @@ from .spatial_cross_attention import MSDeformableAttention3D
 from .decoder import CustomMSDeformableAttention
 from mmcv.runner import force_fp32, auto_fp16
 
-@TRANSFORMER.register_module()
+@TRANSFORMER.register_module(force=True)
 class PerceptionTransformer(BaseModule):
     """Implements the Detr3D transformer.
     Args:
diff --git a/tools/analysis_tools/benchmark.py b/tools/analysis_tools/benchmark.py
index 9056422..72988ba 100755
--- a/tools/analysis_tools/benchmark.py
+++ b/tools/analysis_tools/benchmark.py
@@ -9,9 +9,9 @@ import sys
 sys.path.append('.')
 from projects.mmdet3d_plugin.datasets.builder import build_dataloader
 from projects.mmdet3d_plugin.datasets import custom_build_dataset
-# from mmdet3d.datasets import build_dataloader, build_dataset
-from mmdet3d.models import build_detector
-#from tools.misc.fuse_conv_bn import fuse_module
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.models import build_detector
 
 
 def parse_args():
diff --git a/tools/analysis_tools/visualize/run.py b/tools/analysis_tools/visualize/run.py
index 73b5219..f421324 100644
--- a/tools/analysis_tools/visualize/run.py
+++ b/tools/analysis_tools/visualize/run.py
@@ -5,17 +5,17 @@ import os
 import glob
 import numpy as np
 import mmcv
-import matplotlib
-import matplotlib.pyplot as plt
+# import matplotlib
+# import matplotlib.pyplot as plt
 from nuscenes import NuScenes
-from nuscenes.prediction import PredictHelper, convert_local_coords_to_global
-from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix
-from nuscenes.utils.data_classes import LidarPointCloud, Box
+from nuscenes.prediction import PredictHelper#, convert_local_coords_to_global
+# from nuscenes.utils.geometry_utils import view_points, box_in_image, BoxVisibility, transform_matrix
+# from nuscenes.utils.data_classes import LidarPointCloud, Box
 from nuscenes.utils import splits
-from pyquaternion import Quaternion
-from projects.mmdet3d_plugin.datasets.nuscenes_e2e_dataset import obtain_map_info
+# from pyquaternion import Quaternion
+# from projects.mmdet3d_plugin.datasets.nuscenes_e2e_dataset import obtain_map_info
 from projects.mmdet3d_plugin.datasets.eval_utils.map_api import NuScenesMap
-from PIL import Image
+# from PIL import Image
 from tools.analysis_tools.visualize.utils import color_mapping, AgentPredictionData
 from tools.analysis_tools.visualize.render.bev_render import BEVRender
 from tools.analysis_tools.visualize.render.cam_render import CameraRender
@@ -281,6 +281,24 @@ class Visualizer:
             out.write(img_array[i])
         out.release()
 
+def to_video(folder_path, out_path, fps=4, downsample=1):
+    imgs_path = glob.glob(os.path.join(folder_path, '*.jpg'))
+    imgs_path = sorted(imgs_path)
+    img_array = []
+    for img_path in imgs_path:
+        img = cv2.imread(img_path)
+        height, width, channel = img.shape
+        img = cv2.resize(img, (width//downsample, height //
+                            downsample), interpolation=cv2.INTER_AREA)
+        height, width, channel = img.shape
+        size = (width, height)
+        img_array.append(img)
+    out = cv2.VideoWriter(
+        out_path, cv2.VideoWriter_fourcc(*'DIVX'), fps, size)
+    for i in range(len(img_array)):
+        out.write(img_array[i])
+    out.release() 
+
 def main(args):
     render_cfg = dict(
         with_occ_map=False,
@@ -296,8 +314,10 @@ def main(args):
         show_legend=True,
         show_sdc_traj=False
     )
-
-    viser = Visualizer(version='v1.0-mini', predroot=args.predroot, dataroot='data/nuscenes', **render_cfg)
+    to_video('/home/labuser/bjyang/UniAD_train/UniAD/output/tiny_e2e_img_videos/selected', 
+             '/home/labuser/bjyang/UniAD_train/UniAD/output/tiny_e2e_img_videos/selected/tiny_e2e_torch1.12_438-552.avi', fps=4, downsample=2)
+    import pdb; pdb.set_trace()
+    viser = Visualizer(version='v1.0-trainval', predroot=args.predroot, dataroot='data/nuscenes', **render_cfg)
 
     if not os.path.exists(args.out_folder):
         os.makedirs(args.out_folder)
diff --git a/tools/data_converter/uniad_nuscenes_converter.py b/tools/data_converter/uniad_nuscenes_converter.py
index 3b41d40..a6319b5 100644
--- a/tools/data_converter/uniad_nuscenes_converter.py
+++ b/tools/data_converter/uniad_nuscenes_converter.py
@@ -10,8 +10,10 @@ from pyquaternion import Quaternion
 from shapely.geometry import MultiPoint, box
 from typing import List, Tuple, Union
 
-from mmdet3d.core.bbox.box_np_ops import points_cam2img
-from mmdet3d.datasets import NuScenesDataset
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.core.bbox import points_cam2img
+from third_party.uniad_mmdet3d.datasets import NuScenesDataset
 
 nus_categories = ('car', 'truck', 'trailer', 'bus', 'construction_vehicle',
                   'bicycle', 'motorcycle', 'pedestrian', 'traffic_cone',
diff --git a/tools/test.py b/tools/test.py
index d4bf51d..b259e81 100755
--- a/tools/test.py
+++ b/tools/test.py
@@ -11,10 +11,10 @@ from mmcv.parallel import MMDataParallel, MMDistributedDataParallel
 from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,
                          wrap_fp16_model)
 
-from mmdet3d.apis import single_gpu_test
-from mmdet3d.datasets import build_dataset
-from projects.mmdet3d_plugin.datasets.builder import build_dataloader
-from mmdet3d.models import build_model
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.datasets.builder import build_dataloader, build_dataset
+from third_party.uniad_mmdet3d.models.builder import build_model
 from mmdet.apis import set_random_seed
 from projects.mmdet3d_plugin.uniad.apis.test import custom_multi_gpu_test
 from mmdet.datasets import replace_ImageToTensor
@@ -258,4 +258,5 @@ def main():
 
 
 if __name__ == '__main__':
+    torch.multiprocessing.set_start_method('fork')
     main()
diff --git a/tools/train.py b/tools/train.py
index f240c5a..2f18a08 100755
--- a/tools/train.py
+++ b/tools/train.py
@@ -14,13 +14,14 @@ from mmcv.runner import get_dist_info, init_dist
 from os import path as osp
 
 from mmdet import __version__ as mmdet_version
-from mmdet3d import __version__ as mmdet3d_version
 
-from mmdet3d.datasets import build_dataset
-from mmdet3d.models import build_model
-from mmdet3d.utils import collect_env, get_root_logger
+import sys
+sys.path.insert(1, '/home/labuser/bjyang/BEVFormer_tensorrt')
+from third_party.uniad_mmdet3d.datasets.builder import build_dataset
+from third_party.uniad_mmdet3d.models.builder import build_model
+from third_party.uniad_mmdet3d.utils import collect_env, get_root_logger
 from mmdet.apis import set_random_seed
-from mmseg import __version__ as mmseg_version
+# from mmseg import __version__ as mmseg_version
 
 warnings.filterwarnings("ignore")
 
@@ -213,6 +214,10 @@ def main():
         cfg.model,
         train_cfg=cfg.get('train_cfg'),
         test_cfg=cfg.get('test_cfg'))
+    # text_file = open("model_dict_keys.log", 'w')
+    # import pdb; pdb.set_trace()
+    # text_file.write(str(model.state_dict().keys()))
+    # text_file.close()
     model.init_weights()
 
     logger.info(f'Model:\n{model}')
@@ -234,8 +239,8 @@ def main():
         # checkpoints as meta data
         cfg.checkpoint_config.meta = dict(
             mmdet_version=mmdet_version,
-            mmseg_version=mmseg_version,
-            mmdet3d_version=mmdet3d_version,
+            mmseg_version='do not import mmseg',
+            mmdet3d_version='my_custom_mmdet3d',
             config=cfg.pretty_text,
             CLASSES=datasets[0].CLASSES,
             PALETTE=datasets[0].PALETTE  # for segmentors
@@ -253,4 +258,5 @@ def main():
 
 
 if __name__ == '__main__':
+    torch.multiprocessing.set_start_method('fork')
     main()
diff --git a/tools/uniad_dist_eval.sh b/tools/uniad_dist_eval.sh
index d3c84d6..1f4d05f 100755
--- a/tools/uniad_dist_eval.sh
+++ b/tools/uniad_dist_eval.sh
@@ -10,7 +10,7 @@ GPUS=$3                                              #
 # -------------------------------------------------- #
 GPUS_PER_NODE=$(($GPUS<8?$GPUS:8))
 
-MASTER_PORT=${MASTER_PORT:-28596}
+MASTER_PORT=${MASTER_PORT:-28591}
 WORK_DIR=$(echo ${CFG%.*} | sed -e "s/configs/work_dirs/g")/
 # Intermediate files and logs will be saved to UniAD/projects/work_dirs/
 
diff --git a/tools/uniad_dist_train.sh b/tools/uniad_dist_train.sh
index 2febf37..9bc1d1c 100755
--- a/tools/uniad_dist_train.sh
+++ b/tools/uniad_dist_train.sh
@@ -10,7 +10,7 @@ GPUS=$2                                              #
 GPUS_PER_NODE=$(($GPUS<8?$GPUS:8))
 NNODES=`expr $GPUS / $GPUS_PER_NODE`
 
-MASTER_PORT=${MASTER_PORT:-28596}
+MASTER_PORT=${MASTER_PORT:-28599}
 MASTER_ADDR=${MASTER_ADDR:-"127.0.0.1"}
 RANK=${RANK:-0}
 
diff --git a/tools/uniad_vis_result.sh b/tools/uniad_vis_result.sh
index b43a1be..60ed890 100755
--- a/tools/uniad_vis_result.sh
+++ b/tools/uniad_vis_result.sh
@@ -1,7 +1,7 @@
-#!/bin/bash
+#!/usr/bin/env bash
 
+PYTHONPATH="$(dirname $0)/..":$PYTHONPATH \
 python ./tools/analysis_tools/visualize/run.py \
-    --predroot PATH_TO_YOUR_PREDISION_RESULT_PKL \
-    --out_folder PATH_TO_YOUR_OUTPUT_FOLDER \
-    --demo_video FILENAME_OF_OUTPUT_VIDEO \
-    --project_to_cam True
\ No newline at end of file
+ --predroot /home/labuser/bjyang/UniAD_train/UniAD/data/results_tiny_e2e.pkl  \
+ --out_folder ./output/tiny_e2e_img_videos/  \
+ --demo_video tiny_e2e_torch1.12_438-552.avi --project_to_cam True
\ No newline at end of file
